---
title: "P8105 Homework 5"
output: github_document
date: "2025-11-06 Hantang Qin"
---



```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)

library(tidyverse)
library(broom)
library(purrr)
library(dplyr)


library(ggplot2)
set.seed(0416)
knitr::opts_chunk$set(
  fig.path   = "plots_hw5/",   
  fig.width  = 15, fig.height = 8,
  dpi        = 320,
  fig.retina = 2,            
  dev        = "png"       
)
```



# Problem 1


```{r p1-function}

sim_has_match = function(n) {
  birthdays = sample(1:365, size = n, replace = TRUE)
  
  any(duplicated(birthdays))
}

set.seed(1)

group_sizes = 2:50       
n_sims      = 10000     

birthday_results =
  tibble(group_size = group_sizes) %>%
  mutate(
    prob_match = map_dbl(
      group_size,
      ~ {
        logical_vec = replicate(n_sims, sim_has_match(.x))
        mean(logical_vec)
      }
    )
  )

birthday_results

```


```{r p1-plot}
birthday_results %>%
  ggplot(aes(x = group_size, y = prob_match)) +
  geom_line() +
  geom_point() +
  labs(
    x = "Group size (n)",
    y = "Estimated probability of at least one shared birthday",
    title = "Estimated probability of a shared birthday vs group size"
  ) +
  theme_minimal()

```

When the group size get to about 23 people, the probability that at least two share a birthday is already around 50% and continues to increase as the group gets larger. Once the group size is above about 45 people, that probability is very high and is closer to 1.

---

# Problem 2


```{r p2-function}

set.seed(2)

n       = 30
sigma   = 5
mu_vec  = 0:6      
n_sims  = 5000     

sim_t_once = function(mu, n = 30, sigma = 5) {
  x = rnorm(n, mean = mu, sd = sigma)
  
  test_res = t.test(x, mu = 0)
  
  tidy_res = broom::tidy(test_res)
  
  tibble(
    mu       = mu,                 
    estimate = tidy_res$estimate, 
    p_value  = tidy_res$p.value  
  )
}

sim_results =
  map_dfr(mu_vec, ~ {
    sims = replicate(n_sims, sim_t_once(.x, n = n, sigma = sigma),
                     simplify = FALSE)
    bind_rows(sims)
  })


glimpse(sim_results)

```

## Power vs true Î¼

```{r p2-power}
power_results =
  sim_results %>%
  group_by(mu) %>%
  summarize(
    power = mean(p_value < 0.05),
    .groups = "drop"
  )

power_results %>%
  filter(mu > 0) %>%                 # drop mu = 0
  ggplot(aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 1:6) +
  scale_y_continuous(limits = c(0, 1),
                     breaks = seq(0, 1, by = 0.25)) +
  labs(
    x = "True mean (mu)",
    y = "Power (Pr(reject H0))",
    title = "Power of one-sample t-test vs true mean"
  ) +
  theme_minimal()


```

When the true effect is larger, it becomes easier to detect, meaning that a larger effect size is associated with higher power.


```{r p2-bias}
est_results =
  sim_results %>%
  filter(mu > 0) %>%                     
  group_by(mu) %>%
  summarize(
    mu_hat          = mean(estimate),                 
    rejected_mu_hat = mean(estimate[p_value < 0.05]), 
    .groups = "drop"
  )

est_results  

# make the plot
Averageestimateplot2 =
  est_results %>%
  pivot_longer(
    mu_hat:rejected_mu_hat,
    names_to  = "type",
    values_to = "mu_esti"
  ) %>%
  ggplot(aes(x = mu, y = mu_esti, colour = type)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = seq(0, 6, by = 1)) +    
  scale_y_continuous(breaks = seq(0, 6, by = 1)) +
  labs(
    title = "Average estimate vs True Mean",
    x = "True Mean",
    y = "Average estimate"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

Averageestimateplot2


```


The sample average of \hat{\mu} over all simulated tests is approximately equal to the true value \mu, because \hat{\mu} is an unbiased estimator. Between the two conditions, this overall sample mean is therefore the most accurate predictor. In contrast, when we take the sample average of \hat{\mu} only across tests for which the null hypothesis is rejected, this conditional mean tends to be larger than the true \mu, since small estimates are unlikely to lead to rejection and are effectively removed. As \mu increases and the power of the test grows, it becomes harder to accept the null hypothesis, fewer small values are filtered out, and the sample average of \hat{\mu} given rejection moves closer to the true value \mu, which is consistent with the pattern shown in the plot.`



---

# Problem 3


```{r p3-import}
homicide_raw =
  read_csv("homicide-data.csv") %>%   
  janitor::clean_names()

homicide_raw
```

Dataset contains `r length(colnames(homicide_raw))` variables and `r length(homicide_raw$uid)` observations from `r length(unique(homicide_raw$state))` states. There are `r length(homicide_raw$victim_race)` recorded victim race entries. Key variables include victim demographics  like:  age, race, sex, last name, and case disposition.



```{r p3-summary}
homicide_city =
  homicide_raw %>%
  mutate(
    city_state = str_c(city, state, sep = ", ")
  ) %>%
  group_by(city_state) %>%
  summarize(
    total_homicides = n(),
    unsolved = sum(
      disposition %in% c("Closed without arrest", "Open/No arrest")
    )
  )

homicide_city
```


```{r p3-baltimore}
baltimore =
  homicide_city %>%
  filter(city_state == "Baltimore, MD")

baltimore

```


 In Baltimore, MD, there were 2,827 homicides in the dataset, and 1,825 of these were unsolved, which is about 65% of all cases.



```{r p3-map}
city_results =
  homicide_city %>%
  mutate(
    prop_test = map2(
      unsolved,
      total_homicides,
      ~ prop.test(x = .x, n = .y)
    ),
    prop_tidy = map(prop_test, broom::tidy)
  ) %>%
  unnest(prop_tidy)

city_results
```


```{r p3-plot, fig.height = 8}

city_results %>%
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0) +
  coord_flip() +
  labs(
    x = "City",
    y = "Estimated proportion of unsolved homicides",
    title = "Unsolved homicides by city with 95% confidence intervals"
  ) +
  theme_minimal()
```



